---
title: "Python SDK"
description: "Setting up Langtrace Python SDK with OTEL Collector"
---

## Overview

This guide will walk you through the steps to setup Langtrace's python SDK with OpenTelemetry (OTEL) Collector using.

## Configurations

### OTEL Collector

Refer to the OTEL configuration page on how to run and configure the OpenTelemetry Collector with a custom configuration file.

[OTEL Configuration](./otel-configuration)

### Python SDK Configuration

To send traces from your python project to the collector, use the following code snippet.

<AccordionGroup>
  <Accordion title="Example setup steps">

    Create a folder and setup a virtual env for python
    ```bash
    mkdir langtrace-otel
    touch main.py
    python3 -m venv venv
    source venv/bin/activate
    ```

    Install openai and Langtrace python SDK
    ```bash
    pip install openai langtrace-python-sdk
    ```

    Export OpenAI key:
    ```bash
    export OPENAI_API_KEY="your-openai-api-key"
    ```

  </Accordion>

</AccordionGroup>

Install the OpenTelemetry exporter package:

```bash
pip install opentelemetry-exporter-otlp-proto-http
```

## Implementation

Initialize Langtrace SDK with the custom remote exporter that uses the OTLPTraceExporter to send traces.

```python
from langtrace_python_sdk import langtrace
from openai import OpenAI
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter


# Configure the OTLP exporter to use the correct endpoint
otlp_endpoint = "http://localhost:4318/v1/traces"
otlp_exporter = OTLPSpanExporter(
    endpoint=otlp_endpoint,
    headers=(("Content-Type", "application/json"),))
langtrace.init(custom_remote_exporter=otlp_exporter, batch=False)


def chat_with_openai():
    client = OpenAI()
    messages = [
      {
          "role": "system",
          "content": "How many states of matter are there?",
      },
    ]
    chat_completion = client.chat.completions.create(
        messages=messages,
        stream=False,
        model="gpt-3.5-turbo",
    )
    print(chat_completion.choices[0].message.content)


chat_with_openai()
```

Run the script

```bash
python main.py
```

## Conclusion

By following this guide, you will have OpenTelemetry support added to your Python project, enabling you to send traces to an OpenTelemetry backend including Langtrace's Cloud or self-hosted setup.
