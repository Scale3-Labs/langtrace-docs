---
title: "TypeScript SDK"
description: "Setting up Langtrace Typescript SDK with OTEL Collector"
---

## Overview

This guide will walk you through the steps to setup Langtrace with OpenTelemetry (OTEL) Collector using the HTTP/JSON protocol in a TypeScript project.

## Configurations

### OTEL Collector

Refer to the OTEL configuration page on how to run and configure the OpenTelemetry Collector with a custom configuration file.

[OTEL Configuration](./otel-configuration)

### TypeScript SDK

To send traces from your TypeScript project to Langtrace, use the following code snippet. Update the API key and endpoint as necessary.

Install the OpenTelemetry HTTP/JSON exporter package:

```bash
npm install @opentelemetry/exporter-trace-otlp-http
```

## Implementation

Initialize Langtrace SDK with the custom remote exporter that uses the OTLPTraceExporter to send traces to Langtrace Cloud or your self-hosted Langtrace instance.

<AccordionGroup>
  <Accordion title="Example setup steps">

    Create a folder and setup a project
    ```bash
    mkdir langtrace-otel
    touch your-script.js
    npm init -y
    ```

    Edit the package.json and add type: module so we can run JS files directly
    ```json
    {
      ...
      "type": "module",
      ...
    }
    ```

    Install the required packages:
    ```bash
      npm i openai @langtrase/typescript-sdk @opentelemetry/exporter-trace-otlp-http
    ```

    Export OpenAI key:
    ```bash
    export OPENAI_API_KEY="your-openai-api-key"
    ```

  </Accordion>

</AccordionGroup>

```typescript
import * as Langtrace from "@langtrase/typescript-sdk";
import { OTLPTraceExporter } from "@opentelemetry/exporter-trace-otlp-http";
import OpenAI from "openai";

Langtrace.init({
	batch: false,
	custom_remote_exporter: new OTLPTraceExporter({
		url: "http://localhost:4318/v1/traces",
	}),
	instrumentations: {
		openai: OpenAI,
	},
});

const openai = new OpenAI();

export async function example() {
	const completion = await openai.chat.completions.create({
		model: "gpt-4o-mini",
		messages: [
			{
				role: "system",
				content: "How many states of matter are there?",
			},
		],
	});
	console.log(completion.choices[0]);
}

await example();
```

Run the script

```bash
node your-script.js
```

<Info>
	Ignore the following Warning message from Langtrace SDK:
```bash
No API key provided. Please provide an API key to start sending traces to Langtrace.
```

</Info>

## Conclusion

By following this guide, you will have OpenTelemetry support added to your TypeScript project, enabling you to send traces to Langtrace Cloud or your self-hosted Langtrace instance using the HTTP/JSON protocol.
