---
title: "LiteLLM"
description: "Langtrace and LiteLLM Integration Guide"
---

Langtrace integrates directly with LiteLLM, offering detailed, real-time insights into performance metrics such as cost, token usage, accuracy, and latency.

## Setup

1. Install Langtrace's SDK and [initialize](/quickstart) the SDK in your code.

*Note: You'll need API key from Langtrace. Sign up for [Langtrace](https://langtrace.ai) if you haven't done so already.*

```bash Python
# Install the SDK
pip install -U langtrace-python-sdk
```

2. Setup environment variables:
```bash Shell
export LANGTRACE_API_KEY=YOUR_LANGTRACE_API_KEY
```

## Usage

Generate a simple output with your deployment's model:

<CodeGroup>
```python Python
import os
from langtrace_python_sdk import langtrace # Must precede any llm module imports
langtrace.init(api_key = os.environ['LANGTRACE_API_KEY'])

# Your code here

```
</CodeGroup>

You can now view your traces on the Langtrace dashboard
![traces](/images/litellm.png)

Want to see more supported methods? Checkout the sample code in the [Langtrace Langchain Python Example](https://python.langchain.com/docs/get_started/installation/)