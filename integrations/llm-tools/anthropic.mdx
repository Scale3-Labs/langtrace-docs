---
title: Anthropic
description: Anthropic is an AI research organization behind Claude model family. Whether you're brainstorming alone or building with a team of thousands, Claude is here to help.
---

Using Langtrace to monitor your Claude backed LLM apps is quick and easy. Follow these steps:

## Setup

1. Install Langtrace's SDK and [initialize](/quickstart) the SDK in your code.

*Note: You'll need API keys from Langtrace and Anthropic. Sign up for [Langtrace](https://langtrace.ai) and/or [Anthropic](https://www.anthropic.com/) if you haven't done so already.*

```bash Python
# Install the SDK
pip install -U langtrace-python-sdk anthropic
```

2. Setup environment variables:
```bash Shell
export LANGTRACE_API_KEY=YOUR_LANGTRACE_API_KEY
export ANTHROPIC_API_KEY=YOUR_ANTHROPIC_API_KEY
```

## Usage
Generate a simple output with your deployment's model:

<CodeGroup>
    ```python Python
# Imports import os
import os
from langtrace_python_sdk import langtrace # Must precede any llm module imports
langtrace.init(api_key = os.environ['LANGTRACE_API_KEY'])
from anthropic import Anthropic
client = Anthropic(
    # This is the default and can be omitted
    api_key=os.environ.get("ANTHROPIC_API_KEY"),
)

# Query Anthropic's claude-3-opus MODEL:
message = client.messages.create(
    max_tokens=1024,
    messages=[
        {
            "role": "user",
            "content": "Hello, Claude",
        }
    ],
    model="claude-3-opus-20240229",
)
print(message)
````
</CodeGroup>

You can now view your traces on the Langtrace dashboard

![traces](/images/anthropic.png)

Want to see more supported methods? Checkout the sample code in the [Langtrace Anthropic Python Example](https://github.com/Scale3-Labs/langtrace-recipes/blob/main/integrations/language-model/anthropic/starter.ipynb) repository.
